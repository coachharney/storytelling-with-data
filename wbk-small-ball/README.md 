# Ivy League Women’s Basketball Small Ball Data

This repository contains cumulative boxscores for each Ivy League Women’s Basketball team from seasons 2011-2012 to 2016-2017. course materials for the Dartmouth Course [Storytelling with Data (PSYC 81.06)](http://pbs.dartmouth.edu/undergraduate/permission-courses/fall-2017).  The syllabus may be found [[here](https://github.com/ContextLab/storytelling-with-data/blob/master/admin/PSYC_81_syllabus.pdf)].

## Student instructions

**If you are a student enrolled in the class (or if you'd like to following along!) you should start by signing up for the course's [Slack account](stories-about-data.slack.com) (you need to join using your @dartmouth.edu email address).**

Next, run through this [GitHub tutorial](https://try.github.io).  Then fork this repository so that you can contribute!

All code for this course should be written in [Python](https://www.python.org/) and organized in a [Jupyter notebook](http://jupyter.org/).  Any data you analyze must be shareable with all other students in the course, and ideally it should be shareable with the public.  All code and other student-generated materials will be shared publically.

We will use [Docker](https://www.docker.com/) as a platform for running code, managing software, etc.  Docker is a tool for packaging up everything programs need to run into isolated "containers" that can run on anybody's computer.  (You can always attempt to install packages that we use in the course via other means, but Docker is the only *supported* method.)  To get Docker set up on your machine, following [these instructions](https://github.com/ContextLab/storytelling-with-data/blob/master/docker/README.md).

## Tutorials

In addition to the GitHub tutorial above, if you're new to computer programming, Python, or Jupyter notebooks, you'll want to run through some tutorials to help you get started.  We'll go over the very high-level ideas in class, and you can always ask questions in class or via Slack, but you will likely need to go through these tutorials on your own time to fully experience the delicious learning benefits encapsulated within.

- Introduction to [Python](https://www.codecademy.com/learn/learn-python) (beginner)
- Introduction to [Git](https://www.codecademy.com/learn/learn-git) (beginner)
- Video introduction to [Jupyter Notebooks](https://www.youtube.com/watch?v=e9cSF3eVQv0) (with [code](https://github.com/alfredessa/awesomedata.science/tree/master/1.0JupyterTour)) (beginner)
- Learning to code with [Python *and* Jupyter Notebooks](http://introtopython.org/) (beginner)

Once you have the basics down, you can move on to learn about some very useful Python packages:

- Introduction to [Pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html) (intermediate)
- Practice your Pandas [skills](https://github.com/guipsamora/pandas_exercises) (intermediate)
- Getting started with [Numpy](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html) (intermediate)
- Getting started with [Scipy](https://docs.scipy.org/doc/scipy/reference/tutorial/index.html) (intermediate)
- Exploring high dimensional data with [HyperTools](http://blog.kaggle.com/2017/04/10/exploring-the-structure-of-high-dimensional-data-with-hypertools-in-kaggle-kernels/) (intermediate)

Another really useful technique for doing reproducible open science in the real world is to develop [unit tests](http://docs.python-guide.org/en/latest/writing/tests/).  I suggest using [Travis CI](https://docs.travis-ci.com/) to automatically run your unit tests when you check in new code:
- Testing applications with [Pytest](https://semaphoreci.com/community/tutorials/testing-python-applications-with-pytest) (advanced)
- Setting up [Travis CI](https://docs.travis-ci.com/user/for-beginners) (advanced)

Domain-specific tutorials:
- [Tools for analyzing dynamic brain patterns and brain networks](https://github.com/Summer-MIND/mind_2017) (intermediate to advanced)

## Where to find nice datasets

In todays "Big Data" world, there are an abundance of high-quality, free datasets to enjoy and explore.  Below is a short list of websites that are great resources for data:

- [Kaggle](https://www.kaggle.com/datasets)
- [FiveThirtyEight](https://github.com/fivethirtyeight/data)
- [Awesome Public Datasets](https://github.com/caesar0301/awesome-public-datasets)
- [Datalad](http://datasets.datalad.org/)
- [Princeton Neuroscience Institute](http://dataspace.princeton.edu/jspui/handle/88435/dsp0147429c369)

## The *data-stories* folder

Each time you begin a new project, you should (in collaboration with your project team):
- Fork this repository and clone it to your computer
- Come up with a creative, fun, yet descriptive, name for your project
- Create a new project sub-folder under [data-stories](https://github.com/ContextLab/storytelling-with-data/tree/master/data-stories)
- Follow the instructions [here](https://github.com/ContextLab/storytelling-with-data/tree/master/data-stories/README.md) to finish setting up your project
- When you have something good or shareable, submit a *pull request* to merge your fork into master (the "original fork").  If your request is accepted, your project will now become part of the main repository for this course.  That's called "sharing."

You can also (when the mood strikes) continue, or fork, *someone else's project* -- in the real world, this is called (amongst other things) "doing science."  Or, as Bernard of Chartres, and more recently Isaac Newton, described it, "standing on the shoulders of giants."  To stand on the shoulders of someone else's project, follow a similar procedure to what's described above:
- Create a new fork of this repository, possibly based off of someone else's fork (if they'll share it with you!)
- Decide whether your changes merit a new project name (new folder) or whether you want to add to the existing project (existing folder)
- Follow the regular [project setup instructions](https://github.com/ContextLab/storytelling-with-data/tree/master/data-stories/README.md), modifying as needed
- When you have something to share, submit a pull request so that everyone can benefit from your work.  If you're feeliing extra nice, it's never a bad idea to acknowledge the original project on which your work is based (e.g. in your project's readme file), and/or to give the original project's authors a heads up that you're about to change the world using something they started!

## Getting help

Data science is a tricky, rewarding, and often frustrating business.  Luckily for us data scientists, there are many places to get help!  Examples include:
- [Google](http://www.google.com)-- searchable portal to of all human knowledge. Most Internet things are reachable through here, and it's a great place to start your search.  You can often find code that other people have written that solves a similar problem to the one you're working on, or a tutorial that teaches you how to solve a particular class of problems.
- [Wikipedia](https://www.wikipedia.org/)-- community-curated encyclopedia. Wikipedia is a good resource for learning about the background of a technique, looking up equations, etc.  It's not a good source for tutorials.
- [Slack](https://stories-about-data.slack.com)-- course chatroom.  A good place to ask questions, post ideas, etc., to other members of the class.
- The last (but hopefully not least) option if you're feeling stuck, unhappy with how things are progressing, looking for fun new ideas to revitalize your project and get you interested in science again, etc. is to *come talk with me*.  If you're a Dartmouth person you can come to my regular office hours, [email me](mailto:jeremy@dartmouth.edu), message me on Slack, or come visit [my lab](http://www.context-lab.com/).
- **Important**-- chances are good that if you're feeling lost, you're not the only one!  If you learn something useful, please share it via Slack!
